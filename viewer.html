<!doctype html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/>
    <title>AI Avatar Viewer (WebRTC)</title>
    <style>
      html,body{margin:0;padding:0;height:100%;width:100%;background:#0b0b0c;color:#eaeaea;font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif}
      .wrap{display:flex;flex-direction:column;gap:8px;width:100%;height:100%;align-items:center;justify-content:flex-start}
      .title{font-size:15px;text-align:center;margin-top:6px;opacity:.9}
      .stage{
        position:relative;width:100%;max-width:420px;
        aspect-ratio:16/9; /* default; updated to real stream AR after first frame 16/9 */
        background:#111;border-radius:18px;overflow:hidden;border:1px solid #222;
        display:grid;place-items:center
      }
      video{width:100%;height:100%;object-fit:contain;display:block;background:#0b0b0c}
      .status{font-size:12px;opacity:.85}
      .overlay{position:absolute;inset:0;display:flex;align-items:center;justify-content:center;background:rgba(0,0,0,0.25)}
      .overlay button{border:none;border-radius:999px;padding:12px 16px;font-size:14px;cursor:pointer;box-shadow:0 8px 22px rgba(0,0,0,.35)}
    </style>
  </head>
  <body>
    <div class="wrap">
      <div class="title">Avatar: <span id="aname"></span></div>
      <div class="stage" id="stage">
        <video id="video" playsinline autoplay muted></video>
        <div class="overlay" id="audioGate" style="display:flex">
          <button id="enableBtn">ðŸ”Š Tap to enable sound</button>
        </div>
      </div>
      <div class="status" id="status">initializingâ€¦</div>
    </div>

    <audio id="audio" autoplay></audio>

    <script>
      // Injected by Streamlit
      const SESSION_TOKEN = "__SESSION_TOKEN__";
      const AVATAR_NAME   = "__AVATAR_NAME__";
      const SESSION_ID    = "__SESSION_ID__";
      const OFFER_SDP     = "__OFFER_SDP__";
      const RTC_CONFIG    = __RTC_CONFIG__ || {};

      // UI helpers
      const stage   = document.getElementById("stage");
      const video   = document.getElementById("video");
      const audio   = document.getElementById("audio");
      const gate    = document.getElementById("audioGate");
      const btn     = document.getElementById("enableBtn");
      const statusEl= document.getElementById("status");
      document.getElementById("aname").textContent = AVATAR_NAME;
      const setStatus = (t)=> statusEl.textContent = t;

      async function ensureAudio() {
        try { audio.muted = false; audio.volume = 1.0; await audio.play(); gate.style.display = "none"; }
        catch { gate.style.display = "flex"; }
      }
      btn.addEventListener('click', ensureAudio);

      // Adaptive aspect ratio once we know the stream dimensions
      function applyAdaptiveAR() {
        const w = video.videoWidth || 0, h = video.videoHeight || 0;
        if (w > 0 && h > 0) {
          // clamp to sane limits (e.g., avoid extreme tall ratios)
          const ratio = w / h;
          const clamped = Math.max(0.9, Math.min(2.1, ratio)); // ~from 9:10 to ~21:10
          stage.style.aspectRatio = `${clamped} / 1`;
        }
      }
      video.addEventListener("loadedmetadata", applyAdaptiveAR);

      // ---- WebRTC wiring with auto-reconnect ----
      let pc = null;
      let reconnectAttempts = 0;
      const MAX_RETRIES = 3;

      async function startOnce() {
        // Build a fresh RTCPeerConnection
        if (pc) { try { pc.close(); } catch {} pc = null; }
        pc = new RTCPeerConnection(RTC_CONFIG);

        // Ensure we request both tracks
        try {
          pc.addTransceiver("audio", { direction: "recvonly" });
          pc.addTransceiver("video", { direction: "recvonly" });
        } catch {}

        pc.ontrack = (ev) => {
          const [stream] = ev.streams;
          if (!stream) return;
          if (ev.track.kind === "video") {
            video.srcObject = stream;
            video.muted = true;
            video.play().catch(()=>{});
            // If metadata already known, apply AR immediately
            if (video.videoWidth && video.videoHeight) applyAdaptiveAR();
          } else if (ev.track.kind === "audio") {
            audio.srcObject = stream;
            setTimeout(ensureAudio, 100);
          }
        };

        pc.oniceconnectionstatechange = () => {
          const s = pc.iceConnectionState;
          if (s === "connected" || s === "completed") {
            setStatus("connected");
            reconnectAttempts = 0; // reset backoff after a good connection
          } else if (s === "disconnected") {
            setStatus("ice disconnected");
            // soft wait; transient disconnects often recover without action
            setTimeout(() => {
              if (pc && (pc.iceConnectionState === "disconnected" || pc.iceConnectionState === "failed")) {
                triggerReconnect();
              }
            }, 1500);
          } else if (s === "failed") {
            setStatus("ice failed");
            triggerReconnect();
          }
        };

        setStatus("applying offerâ€¦");
        await pc.setRemoteDescription({ type: "offer", sdp: OFFER_SDP });

        setStatus("creating answerâ€¦");
        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);

        // Wait for ICE gathering to finish or timeout
        await new Promise((resolve) => {
          if (pc.iceGatheringState === "complete") return resolve();
          const check = () => {
            if (pc.iceGatheringState === "complete") {
              pc.removeEventListener("icegatheringstatechange", check);
              resolve();
            }
          };
          pc.addEventListener("icegatheringstatechange", check);
          setTimeout(resolve, 1500);
        });

        setStatus("starting sessionâ€¦");
        await fetch("https://api.heygen.com/v1/streaming.start", {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${SESSION_TOKEN}`,
            "Content-Type": "application/json",
            "accept": "application/json"
          },
          body: JSON.stringify({
            session_id: SESSION_ID,
            sdp: { type: "answer", sdp: pc.localDescription.sdp }
          })
        });

        setStatus("waiting for mediaâ€¦");
        gate.style.display = "flex";
      }

      async function triggerReconnect() {
        if (reconnectAttempts >= MAX_RETRIES) {
          setStatus("reconnect limit reached â€” use Start/Restart");
          return;
        }
        reconnectAttempts++;
        const delay = 500 * reconnectAttempts; // simple backoff
        setStatus(`reconnecting (${reconnectAttempts}/${MAX_RETRIES})â€¦`);
        try {
          // small pause helps on mobile networks
          await new Promise(r => setTimeout(r, delay));
          await startOnce();
        } catch (e) {
          console.error("reconnect error", e);
          // try again soon if we still have attempts
          if (reconnectAttempts < MAX_RETRIES) {
            setTimeout(triggerReconnect, 800);
          } else {
            setStatus("reconnect failed â€” use Start/Restart");
          }
        }
      }

      // Kickoff
      (async () => {
        try { await startOnce(); }
        catch (err) { setStatus("init error"); console.error(err); }
      })();
    </script>
  </body>
</html>
